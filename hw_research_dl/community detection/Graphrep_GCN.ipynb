{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from graph_utils import read_graph, cal_gcn_matrix\n",
    "from sampling import EdgeSampler\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#权重矩阵的初始化\n",
    "def xavier_init(fan_in, fan_out, constant=1):\n",
    "    high = constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    low = -high\n",
    "    # 均匀分布\n",
    "    return tf.random_uniform((fan_in, fan_out), minval=low, maxval=high, dtype=tf.float32)\n",
    "\n",
    "class GraRep:\n",
    "    \"\"\"\n",
    "    This is the base class of graph representation network.\n",
    "    \"\"\"\n",
    "    def __init__(self, graph, node_features, embed_dim=64, batch_size=8, learning_rate=1e-4, regularization=0.1):\n",
    "        self.graph = graph\n",
    "        # 计算当前图的节点数量和边的数量\n",
    "        self.node_num = self.graph.number_of_nodes()\n",
    "        self.edge_num = self.graph.number_of_edges()\n",
    "        print(\"EdgeSampler:nodes=%s, edges=%s\"\n",
    "              % (self.node_num, self.edge_num))\n",
    "\n",
    "        self.node_features = node_features#(m*n,理论上m表示节点数，n表示特征维度)\n",
    "        self.feature_dim = self.node_features.shape[1]\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularization = regularization\n",
    "\n",
    "    def _init_params(self):\n",
    "        pass\n",
    "\n",
    "    def _construct_network(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GCN(GraRep):\n",
    "    def __init__(self, completed_graph, node_features, first_layer_dim=64, embed_dim=64\n",
    "                 , neg_num=5, batch_size=100):\n",
    "        super().__init__(completed_graph, node_features, embed_dim=embed_dim\n",
    "                         , learning_rate=1e-4, batch_size=batch_size)\n",
    "        self.neg_num = neg_num\n",
    "        self.node_features = node_features\n",
    "        self.sample_num = self.batch_size * (1 + self.neg_num)\n",
    "        # 正负样本数*batch(每次抓取的样本量)=检验数\n",
    "        self.batch_size = batch_size\n",
    "        self.node_size = self.graph.number_of_nodes()\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        self.first_layer_dim = first_layer_dim\n",
    "\n",
    "        self._init_params()  # 初始化参数\n",
    "        self._construct_network()  # 构造网络\n",
    "        self._optimize_line()  # 开始进行优化，\n",
    "\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # 构造模型参数\n",
    "    def _init_params(self):\n",
    "        '''\n",
    "        注意层层之间的权重和卷积层权重的区别，GCN的卷积层权重是共享的，针对节点级别；\n",
    "        而需要训练的权重参数每层是不一样的，针对特征级别\n",
    "        '''\n",
    "        # 初始化GCN的权重参数和偏置项\n",
    "        self.w0 = tf.Variable(xavier_init(self.feature_dim, self.first_layer_dim))\n",
    "        self.b0 = tf.Variable(tf.zeros([self.first_layer_dim], dtype=tf.float32))\n",
    "        self.w1 = tf.Variable(xavier_init(self.first_layer_dim, self.embed_dim))\n",
    "        self.b1 = tf.Variable(tf.zeros([self.embed_dim], dtype=tf.float32))\n",
    "\n",
    "        # 构造图的邻接矩阵和GCN卷积部分的权重矩阵\n",
    "        self.adj_matrix = self.node_features#直接输入拓扑结构\n",
    "        self.gcn_matrix = np.array(cal_gcn_matrix(self.adj_matrix), np.float32)#权值共享\n",
    "\n",
    "    # 构造网络结构\n",
    "    def _construct_network(self):\n",
    "        print(\"GCN 第一层， gcn_matrix*node_features\")\n",
    "        # 第一层，初始化H为特征向量\n",
    "        print(self.gcn_matrix.dtype)\n",
    "        print(self.node_features.dtype)\n",
    "        #ax = np.matmul(self.gcn_matrix, self.node_features)，将处理过的拉普拉斯矩阵作为特征输入\n",
    "        ax = np.matmul(self.gcn_matrix, self.gcn_matrix)\n",
    "        self.hidden = tf.nn.leaky_relu(tf.add(tf.matmul(ax, self.w0), self.b0))\n",
    "        print(\"GCN 第二层\")\n",
    "        self.embed = tf.nn.leaky_relu(tf.add(tf.matmul(tf.matmul(self.gcn_matrix, self.hidden), self.w1), self.b1))\n",
    "#训练出节点表示\n",
    "    def _optimize_line(self):\n",
    "        \"\"\"\n",
    "        Unsupervised traininig in LINE manner.\n",
    "        \"\"\"\n",
    "        self.u_i = tf.placeholder(name='u_i', dtype=tf.int32, shape=[self.sample_num])\n",
    "        self.u_j = tf.placeholder(name='u_j', dtype=tf.int32, shape=[self.sample_num])\n",
    "        self.label = tf.placeholder(name='label', dtype=tf.float32, shape=[self.sample_num])\n",
    "\n",
    "        self.u_i_embedding = tf.matmul(tf.one_hot(self.u_i, depth=self.node_num, dtype=tf.float32)\n",
    "                                       , self.embed)\n",
    "        #可以推导出one-hot:n*1；embed:n*k(k表示embed的最终维度)，因此计算得来的是u_i的特征表示：k*1\n",
    "        self.u_j_embedding = tf.matmul(tf.one_hot(self.u_j, depth=self.node_num, dtype=tf.float32)\n",
    "                                       , self.embed)\n",
    "        self.inner_product = tf.reduce_sum(self.u_i_embedding * self.u_j_embedding, axis=1)\n",
    "        #理解为向量之间的相似度\n",
    "        self.loss = -tf.reduce_mean(tf.log_sigmoid(self.label * self.inner_product))\n",
    "        #交叉熵损失函数，有边时label=1，minimize loss=maximize 相似度\n",
    "        \n",
    "        # 定义优化器\n",
    "        self.line_optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "\n",
    "    def train_line(self, u_i, u_j, label):\n",
    "        \"\"\"\n",
    "        Train one minibatch.\n",
    "        \"\"\"\n",
    "        feed_dict = {self.u_i: u_i, self.u_j: u_j, self.label: label}\n",
    "        _, loss = self.sess.run((self.line_optimizer, self.loss), feed_dict=feed_dict)\n",
    "        return loss\n",
    "\n",
    "    def cal_encoder_embed(self):\n",
    "        return self.sess.run(self.embed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, ..., 1, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 1, 1],\n",
       "       [0, 0, 1, ..., 1, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取邻接矩阵\n",
    "F = nx.karate_club_graph()\n",
    "adj = np.array(nx.adjacency_matrix(F).todense())\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为节点添加权重\n",
    "for i in list(F.nodes):\n",
    "    F.nodes[i]['weight']=1 # 注意版本，g.node属性已经被弃用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为边添加权重\n",
    "for edge in list(F.edges):\n",
    "    edge_1 = edge[0]\n",
    "    edge_2 = edge[1]\n",
    "    #print(edge_1)\n",
    "    #g[1][2]['weight'] = 4.7\n",
    "    F[edge_1][edge_2]['weight'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_size = F.number_of_nodes()\n",
    "node_attr = np.array(adj, np.float32) # 邻接矩阵\n",
    "neg_num = 5 # 负采样的个数\n",
    "batch_size = 100\n",
    "display_batch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdgeSampler:nodes=34, edges=78\n",
      "GCN 第一层， gcn_matrix*node_features\n",
      "float32\n",
      "float32\n",
      "GCN 第二层\n",
      "进行子图采样\n",
      "EdgeSampler:nodes=34, edges=78\n",
      "Finished edge sampler initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dockerdata/frontier/install/py36_mrc/lib/python3.6/site-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "model = GCN(F, node_attr, neg_num=neg_num, batch_size=batch_size)\n",
    "\n",
    "# 采样的结果是用来计算LOSS\n",
    "print(\"进行子图采样\")\n",
    "sampler_view_graph = EdgeSampler(F, batch_size, neg_num) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.000000: 100%|██████████| 34/34 [00:00<00:00, 76.53it/s]\n"
     ]
    }
   ],
   "source": [
    "avg_loss = 0.\n",
    "total_batch = node_attr.shape[0]\n",
    "\n",
    "with trange(total_batch, desc='loss %8.6f' % 0.) as pbar:\n",
    "    for i in pbar:\n",
    "        u_i, u_j, label = sampler_view_graph.next_batch()\n",
    "        loss = model.train_line(u_i, u_j, label)\n",
    "        avg_loss += loss / display_batch\n",
    "        if i % display_batch == 0 and i > 0:\n",
    "            pbar.set_description('loss %8.6f' % avg_loss)\n",
    "            avg_loss = 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0293884 ,  0.23871067, -0.00122043, ...,  0.37645763,\n",
       "        -0.10584487,  0.01860837],\n",
       "       [-0.00992001,  0.28612608, -0.01248355, ..., -0.0256904 ,\n",
       "        -0.07387978, -0.02090638],\n",
       "       [-0.02338236,  0.11746843, -0.00154851, ...,  0.18492165,\n",
       "        -0.06972755,  0.17885882],\n",
       "       ...,\n",
       "       [ 0.01529879, -0.04324222,  0.02093286, ...,  0.12498906,\n",
       "        -0.03342825, -0.01526836],\n",
       "       [ 0.11964564, -0.00680267,  0.22470786, ...,  0.00816328,\n",
       "        -0.02263976, -0.00905914],\n",
       "       [ 0.20402251, -0.00266688,  0.23170935, ..., -0.06255551,\n",
       "        -0.06614263,  0.10069647]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# node repr \n",
    "base_embed = model.cal_encoder_embed()\n",
    "base_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(base_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Hi\n",
      "Mr. Hi\n",
      "Mr. Hi\n",
      "Mr. Hi\n",
      "Mr. Hi\n",
      "Mr. Hi\n",
      "Mr. Hi\n",
      "Mr. Hi\n",
      "Mr. Hi\n",
      "Officer\n",
      "Mr. Hi\n",
      "Mr. Hi\n",
      "Mr. Hi\n",
      "Mr. Hi\n",
      "Officer\n",
      "Officer\n",
      "Mr. Hi\n",
      "Mr. Hi\n",
      "Officer\n",
      "Mr. Hi\n",
      "Officer\n",
      "Mr. Hi\n",
      "Officer\n",
      "Officer\n",
      "Officer\n",
      "Officer\n",
      "Officer\n",
      "Officer\n",
      "Officer\n",
      "Officer\n",
      "Officer\n",
      "Officer\n",
      "Officer\n",
      "Officer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 16, 17, 19, 21},\n",
       " {9, 14, 15, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hi=[]\n",
    "officer = []\n",
    "for i in range(34):\n",
    "    print(F.nodes[i]['club'])\n",
    "    if F.nodes[i]['club'] == 'Officer':\n",
    "        officer.append(i)\n",
    "    else:\n",
    "        Hi.append(i)\n",
    "l=[]\n",
    "l.append(set(Hi))\n",
    "l.append(set(officer))\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(l1,l2):\n",
    "    sum_1 = 0\n",
    "    sum_2 = 0\n",
    "    #max_ = 0\n",
    "    for i in l1:\n",
    "        max_ = 0\n",
    "        for j in l2:\n",
    "            if len(i&j) > max_:\n",
    "                max_ = len(i&j)\n",
    "                # print(i&j)\n",
    "                flag_ = l2.index(j)\n",
    "        # print(max_,flag_)(测试使用)\n",
    "        sum_1 += max_\n",
    "        sum_2 += len(i)\n",
    "    return sum_1/sum_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{8, 9, 14, 15, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33},\n",
       " {0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 16, 17, 19, 21}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 0\n",
    "for i in list(kmeans.labels_):\n",
    "    l_2[i].add(f)\n",
    "    f += 1\n",
    "l_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9705882352941176\n",
      "0.9705882352941176\n",
      "0.9705882352941176\n"
     ]
    }
   ],
   "source": [
    "print(similarity(l,l_2))\n",
    "print(similarity(l_2,l))\n",
    "print((similarity(l,l_2)+similarity(l_2,l))/2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
